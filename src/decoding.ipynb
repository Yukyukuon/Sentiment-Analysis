{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74242b9-825d-4804-9aaf-45bd8cfa7b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifanjia/miniconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import AutoModelForSequenceClassification, AdamW\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1decb137-26e5-4494-a283-05488d0af101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data_dir = '../data/'\n",
    "train_fname = os.path.join(data_dir, 'traindata.csv')\n",
    "dev_fname = os.path.join(data_dir, 'devdata.csv')\n",
    "colum_names = ['Polarity', 'AspectCategory', 'Term', 'Offsets', 'Sentence']\n",
    "\n",
    "train_data = pd.read_csv(train_fname, delimiter='\\t', header=None, names=colum_names)\n",
    "dev_data = pd.read_csv(dev_fname, delimiter='\\t', header=None, names = colum_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73046061-cf12-407d-aad0-d502242cf5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据转换为 Hugging Face datasets 的 Dataset 对象\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "dev_dataset = Dataset.from_pandas(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb128d02-c311-405e-9dd3-5f6e545459ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41032031-9d69-4cdb-9fea-bc481ad78e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预处理函数\n",
    "def preprocess_function(examples):\n",
    "    # 分离出术语的起始和结束位置\n",
    "    start_offsets, end_offsets = zip(*[(int(offset.split(':')[0]), int(offset.split(':')[1]))\n",
    "                                       for offset in examples['Offsets']])\n",
    "    # 提取术语及其在句子中的上下文\n",
    "    term_contexts = [sentence[start:end] for sentence, start, end in zip(examples['Sentence'], start_offsets, end_offsets)]\n",
    "    # 对句子进行编码，确保同时考虑术语和上下文\n",
    "    encoded_inputs = tokenizer(examples['Sentence'], term_contexts, truncation=True, padding='max_length', max_length=40)\n",
    "    # 将极性标签转换为整数形式\n",
    "    polarity_to_id = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "    encoded_inputs['labels'] = [polarity_to_id[p] for p in examples['Polarity']]\n",
    "\n",
    "    return encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e92c8da-1d12-43f6-a20f-54ab1ebab5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1503/1503 [00:00<00:00, 16736.86 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 376/376 [00:00<00:00, 17096.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 应用预处理\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "dev_dataset = dev_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a999dc-ba2c-454a-9ecf-229e2bb2744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensors(dataset):\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e107588-302d-4b4d-8ee6-62fe30b8b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = convert_to_tensors(train_dataset)\n",
    "dev_dataset = convert_to_tensors(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87104f3b-bb06-42a5-87d5-bc27be436b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0738bb08-11a8-4cbb-9c95-edf1c1083fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc08ca3-56df-42ed-81d4-a9dfd92f58e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67839ba9-5cc2-4e29-8d78-c2057aa4d386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义预训练的BERT模型名字和设备\n",
    "new_dropout_rate = 0.2 \n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "model.dropout.p = new_dropout_rate\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f019d7f1-54fd-4b19-b9ca-1e4000ef7119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b13d1-1e15-4eeb-82ed-0242f4292793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "218196f6-9e7b-4ef4-8806-50e3dde5bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e36b2b33-0412-460f-a561-d34a48028548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0696e4b-9c1b-4c93-b4fe-d9ada41221ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "def train(train_loader, dev_loader, model, optimizer, criterion, device, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_acc =0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            total_acc += (predictions == labels).sum().item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_accuracy = total_acc / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Training Loss: {avg_loss:.4f}, Training Accuracy: {avg_accuracy:.4f}')\n",
    "\n",
    "        evaluate(model, dev_loader, device)\n",
    "\n",
    "def evaluate(model, dev_loader, device):\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            total_eval_accuracy += (predictions == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_eval_loss / len(dev_loader)\n",
    "    accuracy = total_eval_accuracy / len(dev_loader.dataset)\n",
    "    print(f'Validation - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c1a10a8-40e9-426a-8899-a5a994cf0271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training Loss: 0.8017, Training Accuracy: 0.6953\n",
      "Validation - Loss: 0.6973, Accuracy: 0.7048\n",
      "Epoch 2/10 - Training Loss: 0.6608, Training Accuracy: 0.7279\n",
      "Validation - Loss: 0.6182, Accuracy: 0.7261\n",
      "Epoch 3/10 - Training Loss: 0.5599, Training Accuracy: 0.7911\n",
      "Validation - Loss: 0.5294, Accuracy: 0.8085\n",
      "Epoch 4/10 - Training Loss: 0.4892, Training Accuracy: 0.8343\n",
      "Validation - Loss: 0.4807, Accuracy: 0.8351\n",
      "Epoch 5/10 - Training Loss: 0.4344, Training Accuracy: 0.8663\n",
      "Validation - Loss: 0.4569, Accuracy: 0.8378\n",
      "Epoch 6/10 - Training Loss: 0.3827, Training Accuracy: 0.8776\n",
      "Validation - Loss: 0.4391, Accuracy: 0.8511\n",
      "Epoch 7/10 - Training Loss: 0.3543, Training Accuracy: 0.8869\n",
      "Validation - Loss: 0.4437, Accuracy: 0.8564\n",
      "Epoch 8/10 - Training Loss: 0.3277, Training Accuracy: 0.8982\n",
      "Validation - Loss: 0.4366, Accuracy: 0.8564\n",
      "Epoch 9/10 - Training Loss: 0.3007, Training Accuracy: 0.9088\n",
      "Validation - Loss: 0.4386, Accuracy: 0.8484\n",
      "Epoch 10/10 - Training Loss: 0.2862, Training Accuracy: 0.9102\n",
      "Validation - Loss: 0.4459, Accuracy: 0.8537\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, dev_loader, model, optimizer, criterion, device, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a97ab-18ab-46e4-9d1a-a33fe7e1d1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cfc8b0-5c03-4573-ae72-4561df871ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311b991-881a-478c-9123-f6e26878e254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
